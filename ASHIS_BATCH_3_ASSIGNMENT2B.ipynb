{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Done by Name-Ashis Kumar Panda\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Link to Assignment number 1 below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# https://github.com/CaptainAshis/Pandas-/blob/master/TH-INKERS/CS231n-python-numpy-tutorial.ipynb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assignment number 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "|             X            |\n",
    "|------|------|------|-----|\n",
    "|  1   | 0    |   1  |  0  |\n",
    "|------|------|------|-----|\n",
    "|1     |    0 |1     |1    |\n",
    "|------|------|------|-----|\n",
    "|0     |1     |0     |1    |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "|Y|\n",
    "|-|\n",
    "|1|\n",
    "|-|\n",
    "|1|\n",
    "|-|\n",
    "|0|"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# from prettytable import PrettyTable\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "# import pprint"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Declaring input and output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [],
   "source": [
    "X=np.array([[1,0,1,0],[1,0,1,1],[0,1,0,1]])\n",
    "Y=np.array([[1],[1],[0]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 1:- Random Initialisation of Weights and biases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hidden layer weight [[  6.12031177e-01   5.39092721e-02   4.20193680e-01]\n",
      " [  6.79068837e-01   9.18601778e-01   4.02024891e-04]\n",
      " [  9.76759149e-01   3.76580315e-01   9.73783538e-01]\n",
      " [  6.04716101e-01   8.28845808e-01   5.74711505e-01]]\n",
      "\n",
      "hidden layer bias [[ 0.6280762   0.28557628  0.58683334]]\n",
      "\n",
      "output layer weight [[ 0.75002176]\n",
      " [ 0.85831384]\n",
      " [ 0.75508219]]\n",
      "\n",
      "output layer bias [[ 0.69805725]]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "random.seed(1)\n",
    "wh=np.random.rand(4,3)\n",
    "\n",
    "print(\"hidden layer weight\",wh)\n",
    "print()\n",
    "bh=np.random.rand(1,3)\n",
    "bh1=bh\n",
    "print(\"hidden layer bias\",bh)\n",
    "print()\n",
    "wout=np.random.rand(3,1)\n",
    "print(\"output layer weight\",wout)\n",
    "print()\n",
    "bout=np.random.rand(1,1)\n",
    "bout1=bout\n",
    "print(\"output layer bias\",bout)\n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 2:- Calculate hidden layer input:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3, 4)\n",
      "(4, 3)\n",
      "(3, 3)\n",
      "hidden_layer_input [[ 2.21686652  0.71606587  1.98081056]\n",
      " [ 2.82158263  1.54491168  2.55552206]\n",
      " [ 1.91186114  2.03302387  1.16194687]]\n"
     ]
    }
   ],
   "source": [
    "print(X.shape)\n",
    "print(wh.shape)\n",
    "hidden_layer_input = np.dot(X,wh) + bh\n",
    "print(hidden_layer_input.shape)\n",
    "print(\"hidden_layer_input\",hidden_layer_input)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 3: Perform non-linear transformation on hidden linear input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hiddenlayer_activations [[ 0.90175394  0.67174011  0.87876754]\n",
      " [ 0.94383103  0.8241776   0.92794362]\n",
      " [ 0.87122809  0.884221    0.76168629]]\n"
     ]
    }
   ],
   "source": [
    "sigmoid=lambda x: 1 / (1 + np.exp(-x))\n",
    "hiddenlayer_activations = sigmoid(hidden_layer_input)\n",
    "hiddenlayer_activations\n",
    "print(\"hiddenlayer_activations\",hiddenlayer_activations)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 4: Perform linear and non-linear transformation of hidden layer activation at output layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3, 3)\n",
      "(3, 1)\n",
      "(1, 1)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(3, 1)"
      ]
     },
     "execution_count": 182,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(hiddenlayer_activations.shape)\n",
    "print(wout.shape)\n",
    "print(bout.shape)\n",
    "\n",
    "output_layer_input = np.dot(hiddenlayer_activations , wout ) + bout \n",
    "output_layer_input.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3, 1)\n",
      "\n",
      "output [[ 0.87241757]\n",
      " [ 0.88175654]\n",
      " [ 0.86946271]]\n"
     ]
    }
   ],
   "source": [
    "output=sigmoid(output_layer_input)\n",
    "print(output.shape)\n",
    "print()\n",
    "print(\"output\",output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 5: Calculate gradient of Error(E) at output layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [],
   "source": [
    "E = Y-output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 6: Compute slope at output and hidden layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# `Slope_output_layer= derivatives_sigmoid(output)\n",
    "Slope_output_layer=sigmoid(output)*(1-sigmoid(output))\n",
    "# \n",
    "# Slope_hidden_layer = derivatives_sigmoid(hiddenlayer_activations)`\n",
    "Slope_hidden_layer=sigmoid(hiddenlayer_activations)*(1-sigmoid(hiddenlayer_activations))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Slope_output_layer [[ 0.20787306]\n",
      " [ 0.20707393]\n",
      " [ 0.20812497]]\n"
     ]
    }
   ],
   "source": [
    "print(\"Slope_output_layer\",Slope_output_layer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "output [[ 0.87241757]\n",
      " [ 0.88175654]\n",
      " [ 0.86946271]]\n"
     ]
    }
   ],
   "source": [
    "print(\"output\",output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "lr=0.1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 7: Compute delta at output layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3, 1)\n",
      "\n",
      "d_output [[ 0.0026521 ]\n",
      " [ 0.00244851]\n",
      " [-0.01809569]]\n"
     ]
    }
   ],
   "source": [
    "d_output = E * Slope_output_layer*lr\n",
    "print(d_output.shape)\n",
    "print()\n",
    "print(\"d_output\",d_output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 8: Calculate Error at hidden layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3, 3)\n",
      "\n",
      "Error_at_hidden_layer [[ 0.00198913  0.00227633  0.00200255]\n",
      " [ 0.00183644  0.00210159  0.00184883]\n",
      " [-0.01357216 -0.01553178 -0.01366373]]\n"
     ]
    }
   ],
   "source": [
    "Error_at_hidden_layer = np.dot(d_output, wout.T)\n",
    "print(Error_at_hidden_layer.shape)\n",
    "print()\n",
    "print('Error_at_hidden_layer',Error_at_hidden_layer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 9: Compute delta at hidden layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3, 3)\n",
      "\n",
      "d_hiddenlayer [[ 0.00040608  0.00046425  0.00043363]\n",
      " [ 0.00037226  0.00042191  0.00038075]\n",
      " [-0.00292795 -0.00323072 -0.00276823]]\n"
     ]
    }
   ],
   "source": [
    "d_hiddenlayer = Error_at_hidden_layer * Slope_hidden_layer\n",
    "print(d_hiddenlayer.shape)\n",
    "print()\n",
    "print('d_hiddenlayer',d_hiddenlayer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 10: Update weight at both output and hidden layer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "wout [[ 0.74891547]\n",
      " [ 0.85709373]\n",
      " [ 0.75416413]]\n",
      "\n",
      "wh [[  6.12109011e-01   5.39978882e-02   4.20275118e-01]\n",
      " [  6.78776042e-01   9.18278706e-01   1.25201919e-04]\n",
      " [  9.76836983e-01   3.76668931e-01   9.73864976e-01]\n",
      " [  6.04460532e-01   8.28564928e-01   5.74472757e-01]]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "wout = wout + np.dot(hiddenlayer_activations.T, d_output) * lr\n",
    "print()\n",
    "print('wout',wout)\n",
    "wh = wh+ np.dot(X.T,d_hiddenlayer) * lr\n",
    "print()\n",
    "print('wh',wh)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 11: Update biases at both output and hidden layer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "bh [[ 0.62764628  0.28510737  0.58644257]]\n",
      "\n",
      "bout [[ 0.69545823]]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "bh = bh + np.sum(d_hiddenlayer, axis=0) * lr\n",
    "print()\n",
    "print('bh',bh)\n",
    "bout = bout + np.sum(d_output, axis=0)*lr\n",
    "print()\n",
    "print('bout',bout)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 3)"
      ]
     },
     "execution_count": 196,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bh.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 1)"
      ]
     },
     "execution_count": 197,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bout.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert bout1.shape==bout.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "assert bh1.shape==bh.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# -------------------------- COMPLETED --------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "################### Pretty good printing\n",
    "# def pprint(in_table, title):\n",
    "#     out = PrettyTable()\n",
    "#     out.title = title\n",
    "#     out.header = False\n",
    "#     for row in in_table:\n",
    "#         out.add_row(row)\n",
    "#     print(out)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
